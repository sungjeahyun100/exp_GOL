#!/usr/bin/env python3
"""
ê¸°ìš¸ê¸° ì†Œì‹¤ ë¶„ì„: Epoch Loss ë°ì´í„°ì˜ ë¯¸ë¶„ê°’ ê³„ì‚°
"""

import numpy as np
import matplotlib.pyplot as plt
import os
import glob
from pathlib import Path

def load_epoch_loss(file_path):
    """epoch_loss.txt íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ"""
    epochs = []
    losses = []
    
    with open(file_path, 'r') as f:
        for line in f:
            if line.strip():
                parts = line.strip().split()
                if len(parts) >= 2:
                    epochs.append(int(parts[0]))
                    losses.append(float(parts[1]))
    
    return np.array(epochs), np.array(losses)

def calculate_derivatives(epochs, losses):
    """ì†ì‹¤ í•¨ìˆ˜ì˜ 1ì°¨, 2ì°¨ ë¯¸ë¶„ ê³„ì‚°"""
    # 1ì°¨ ë¯¸ë¶„ (ê¸°ìš¸ê¸°)
    dloss_depoch = np.gradient(losses, epochs)
    
    # 2ì°¨ ë¯¸ë¶„ (ê¸°ìš¸ê¸°ì˜ ë³€í™”ìœ¨)
    d2loss_depoch2 = np.gradient(dloss_depoch, epochs)
    
    return dloss_depoch, d2loss_depoch2

def analyze_convergence(epochs, losses, dloss_depoch, d2loss_depoch2, experiment_name):
    """ìˆ˜ë ´ ìƒíƒœ ë¶„ì„"""
    print(f"\n{'='*60}")
    print(f"ğŸ“Š {experiment_name} ë¶„ì„")
    print(f"{'='*60}")
    
    # ê¸°ë³¸ í†µê³„
    print(f"ì´ ì—í­: {len(epochs)}")
    print(f"ì´ˆê¸° ì†ì‹¤: {losses[0]:.6f}")
    print(f"ìµœì¢… ì†ì‹¤: {losses[-1]:.6f}")
    print(f"ì´ ê°œì„ ëŸ‰: {losses[0] - losses[-1]:.6f}")
    
    # ë¯¸ë¶„ê°’ ë¶„ì„
    print(f"\nğŸ” ë¯¸ë¶„ê°’ ë¶„ì„:")
    print(f"í‰ê·  1ì°¨ ë¯¸ë¶„ (ê¸°ìš¸ê¸°): {np.mean(dloss_depoch):.8f}")
    print(f"ìµœì¢… 100ì—í­ í‰ê·  ê¸°ìš¸ê¸°: {np.mean(dloss_depoch[-100:]):.8f}")
    print(f"ìµœì¢… 50ì—í­ í‰ê·  ê¸°ìš¸ê¸°: {np.mean(dloss_depoch[-50:]):.8f}")
    print(f"ìµœì¢… 10ì—í­ í‰ê·  ê¸°ìš¸ê¸°: {np.mean(dloss_depoch[-10:]):.8f}")
    
    # ê¸°ìš¸ê¸° í¬ê¸° (ì ˆëŒ“ê°’)
    abs_gradient = np.abs(dloss_depoch)
    print(f"\nğŸ“‰ ê¸°ìš¸ê¸° í¬ê¸° ë¶„ì„:")
    print(f"í‰ê·  ê¸°ìš¸ê¸° í¬ê¸°: {np.mean(abs_gradient):.8f}")
    print(f"ìµœì¢… 100ì—í­ í‰ê·  ê¸°ìš¸ê¸° í¬ê¸°: {np.mean(abs_gradient[-100:]):.8f}")
    print(f"ìµœì¢… 50ì—í­ í‰ê·  ê¸°ìš¸ê¸° í¬ê¸°: {np.mean(abs_gradient[-50:]):.8f}")
    print(f"ìµœì¢… 10ì—í­ í‰ê·  ê¸°ìš¸ê¸° í¬ê¸°: {np.mean(abs_gradient[-10:]):.8f}")
    
    # ê¸°ìš¸ê¸° ì†Œì‹¤ íŒì •
    final_gradient_magnitude = np.mean(abs_gradient[-50:])
    initial_gradient_magnitude = np.mean(abs_gradient[:50])
    gradient_ratio = final_gradient_magnitude / initial_gradient_magnitude
    
    print(f"\nâš ï¸  ê¸°ìš¸ê¸° ì†Œì‹¤ ë¶„ì„:")
    print(f"ì´ˆê¸° 50ì—í­ í‰ê·  ê¸°ìš¸ê¸° í¬ê¸°: {initial_gradient_magnitude:.8f}")
    print(f"ìµœì¢… 50ì—í­ í‰ê·  ê¸°ìš¸ê¸° í¬ê¸°: {final_gradient_magnitude:.8f}")
    print(f"ê¸°ìš¸ê¸° ë¹„ìœ¨ (ìµœì¢…/ì´ˆê¸°): {gradient_ratio:.4f}")
    
    if gradient_ratio < 0.01:
        print("ğŸš¨ ì‹¬ê°í•œ ê¸°ìš¸ê¸° ì†Œì‹¤ ì˜ì‹¬!")
    elif gradient_ratio < 0.1:
        print("âš ï¸  ê¸°ìš¸ê¸° ì†Œì‹¤ ê°€ëŠ¥ì„± ìˆìŒ")
    elif gradient_ratio < 0.5:
        print("âœ… ì •ìƒì ì¸ ìˆ˜ë ´")
    else:
        print("ğŸ“ˆ í™œë°œí•œ í•™ìŠµ ì§„í–‰")
    
    # ìˆ˜ë ´ ì•ˆì •ì„±
    recent_variance = np.var(losses[-100:])
    print(f"\nğŸ“Š ìˆ˜ë ´ ì•ˆì •ì„±:")
    print(f"ìµœê·¼ 100ì—í­ ì†ì‹¤ ë¶„ì‚°: {recent_variance:.8f}")
    
    return {
        'gradient_ratio': gradient_ratio,
        'final_gradient_magnitude': final_gradient_magnitude,
        'recent_variance': recent_variance,
        'total_improvement': losses[0] - losses[-1]
    }

def plot_derivatives(epochs, losses, dloss_depoch, d2loss_depoch2, experiment_name, output_dir):
    """ë¯¸ë¶„ê°’ ì‹œê°í™”"""
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    
    # 1. ì›ë³¸ Loss ê³¡ì„ 
    axes[0, 0].plot(epochs, losses, 'b-', linewidth=2)
    axes[0, 0].set_title('Loss vs Epoch')
    axes[0, 0].set_xlabel('Epoch')
    axes[0, 0].set_ylabel('Loss')
    axes[0, 0].grid(True, alpha=0.3)
    
    # 2. 1ì°¨ ë¯¸ë¶„ (ê¸°ìš¸ê¸°)
    axes[0, 1].plot(epochs, dloss_depoch, 'r-', linewidth=2)
    axes[0, 1].set_title('Loss Gradient (dLoss/dEpoch)')
    axes[0, 1].set_xlabel('Epoch')
    axes[0, 1].set_ylabel('Gradient')
    axes[0, 1].grid(True, alpha=0.3)
    axes[0, 1].axhline(y=0, color='k', linestyle='--', alpha=0.5)
    
    # 3. ê¸°ìš¸ê¸° í¬ê¸° (ì ˆëŒ“ê°’)
    abs_gradient = np.abs(dloss_depoch)
    axes[1, 0].plot(epochs, abs_gradient, 'g-', linewidth=2)
    axes[1, 0].set_title('Absolute Gradient Magnitude')
    axes[1, 0].set_xlabel('Epoch')
    axes[1, 0].set_ylabel('|Gradient|')
    axes[1, 0].set_yscale('log')  # ë¡œê·¸ ìŠ¤ì¼€ì¼ë¡œ í‘œì‹œ
    axes[1, 0].grid(True, alpha=0.3)
    
    # 4. 2ì°¨ ë¯¸ë¶„ (ê¸°ìš¸ê¸° ë³€í™”ìœ¨)
    axes[1, 1].plot(epochs, d2loss_depoch2, 'm-', linewidth=2)
    axes[1, 1].set_title('Second Derivative (dÂ²Loss/dEpochÂ²)')
    axes[1, 1].set_xlabel('Epoch')
    axes[1, 1].set_ylabel('Second Derivative')
    axes[1, 1].grid(True, alpha=0.3)
    axes[1, 1].axhline(y=0, color='k', linestyle='--', alpha=0.5)
    
    plt.suptitle(f'Gradient Analysis: {experiment_name}', fontsize=16)
    plt.tight_layout()
    
    # ì €ì¥
    output_path = os.path.join(output_dir, f'gradient_analysis_{experiment_name}.png')
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    return output_path

def main():
    # ê·¸ë˜í”„ ë””ë ‰í† ë¦¬ì—ì„œ ëª¨ë“  ì‹¤í—˜ ì°¾ê¸°
    graph_dir = Path("graph")
    
    if not graph_dir.exists():
        print("graph ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    experiments = []
    
    # ëª¨ë“  ì‹¤í—˜ ë””ë ‰í† ë¦¬ íƒìƒ‰
    for exp_dir in graph_dir.iterdir():
        if exp_dir.is_dir():
            epoch_loss_file = exp_dir / "epoch_loss.txt"
            if epoch_loss_file.exists():
                experiments.append({
                    'name': exp_dir.name,
                    'path': exp_dir,
                    'epoch_loss_file': epoch_loss_file
                })
    
    if not experiments:
        print("epoch_loss.txt íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ë°œê²¬ëœ ì‹¤í—˜: {len(experiments)}ê°œ")
    
    # ë¶„ì„ ê²°ê³¼ ì €ì¥ìš©
    analysis_results = []
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_dir = Path("gradient_analysis")
    output_dir.mkdir(exist_ok=True)
    
    # ê° ì‹¤í—˜ ë¶„ì„
    for exp in experiments:
        try:
            # ë°ì´í„° ë¡œë“œ
            epochs, losses = load_epoch_loss(exp['epoch_loss_file'])
            
            if len(epochs) < 10:
                print(f"âš ï¸  {exp['name']}: ë°ì´í„°ê°€ ë„ˆë¬´ ì ìŒ (ì—í­ {len(epochs)}ê°œ)")
                continue
            
            # ë¯¸ë¶„ ê³„ì‚°
            dloss_depoch, d2loss_depoch2 = calculate_derivatives(epochs, losses)
            
            # ë¶„ì„
            result = analyze_convergence(epochs, losses, dloss_depoch, d2loss_depoch2, exp['name'])
            result['experiment_name'] = exp['name']
            analysis_results.append(result)
            
            # ì‹œê°í™”
            plot_path = plot_derivatives(epochs, losses, dloss_depoch, d2loss_depoch2, 
                                       exp['name'], output_dir)
            print(f"ğŸ“Š ê·¸ë˜í”„ ì €ì¥: {plot_path}")
            
        except Exception as e:
            print(f"âŒ {exp['name']} ë¶„ì„ ì‹¤íŒ¨: {e}")
    
    # ì „ì²´ ë¹„êµ ê²°ê³¼
    if analysis_results:
        print(f"\n{'='*80}")
        print("ğŸ† ì‹¤í—˜ ë¹„êµ ìš”ì•½")
        print(f"{'='*80}")
        
        # ê¸°ìš¸ê¸° ì†Œì‹¤ ì •ë„ë¡œ ì •ë ¬
        sorted_results = sorted(analysis_results, key=lambda x: x['gradient_ratio'])
        
        print(f"{'ì‹¤í—˜ëª…':<50} | {'ê¸°ìš¸ê¸°ë¹„ìœ¨':<10} | {'ìµœì¢…ê¸°ìš¸ê¸°':<12} | {'ì´ê°œì„ ëŸ‰':<10}")
        print("-" * 80)
        
        for result in sorted_results:
            name = result['experiment_name']
            if len(name) > 45:
                name = name[:42] + "..."
            
            print(f"{name:<50} | {result['gradient_ratio']:<10.4f} | "
                  f"{result['final_gradient_magnitude']:<12.8f} | "
                  f"{result['total_improvement']:<10.6f}")
        
        # ê¸°ìš¸ê¸° ì†Œì‹¤ ê°€ì¥ ì‹¬í•œ ì‹¤í—˜
        worst_experiment = sorted_results[0]
        best_experiment = sorted_results[-1]
        
        print(f"\nğŸš¨ ê¸°ìš¸ê¸° ì†Œì‹¤ì´ ê°€ì¥ ì‹¬í•œ ì‹¤í—˜:")
        print(f"   {worst_experiment['experiment_name']}")
        print(f"   ê¸°ìš¸ê¸° ë¹„ìœ¨: {worst_experiment['gradient_ratio']:.4f}")
        
        print(f"\nâœ… ê°€ì¥ ê±´ê°•í•œ í•™ìŠµ:")
        print(f"   {best_experiment['experiment_name']}")
        print(f"   ê¸°ìš¸ê¸° ë¹„ìœ¨: {best_experiment['gradient_ratio']:.4f}")

if __name__ == "__main__":
    main()
